---

# Copyright 2024 Wong Hoi Sing Edison <hswong3i@pantarei-design.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Ceph release.
ceph_release: "{{ _ceph_release }}"

# Ceph version.
ceph_version: "{{ _ceph_version[ceph_release] }}"

# Sets the number of replicas for objects in the pool.
ceph_osd_pool_default_size: "{{ (groups['ceph_osd'] | length >= 3) | ternary(3, 1) }}"

# Sets the minimum number of written replicas for objects in the pool in order
# to acknowledge a write operation to the client.
ceph_osd_pool_default_min_size: "{{ (groups['ceph_osd'] | length >= 3) | ternary(2, 1) }}"

# Ceph OSD Pool autoscaler profile.
ceph_osd_pool_autoscale_profile: scale-up

# Ceph Object Storage Daemon configs.
ceph_osd_config:
  - { state: present, section: osd, option: bluefs_buffered_io, value: "true" }
  - { state: present, section: osd, option: bluestore_cache_autotune, value: "false" }
  - { state: present, section: osd, option: bluestore_cache_kv_ratio, value: "0.2" }
  - { state: present, section: osd, option: bluestore_cache_meta_ratio, value: "0.2" }
  - { state: present, section: osd, option: bluestore_cache_size, value: "536870912" }
  - { state: present, section: osd, option: osd_disk_threads, value: "2" }
  - { state: present, section: osd, option: osd_memory_base, value: "402653184" }
  - { state: present, section: osd, option: osd_memory_target, value: "2147483648" }
  - { state: present, section: osd, option: osd_memory_target_autotune, value: "false" }

# Devices to be used as OSDs.
# Device discovery is based on the Ansible fact 'ansible_devices'
# which reports all the devices on a system. If chosen, all the disks
# found will be passed to ceph-volume lvm batch. You should not be worried on using
# this option since ceph-volume has a built-in check which looks for empty devices.
# Thus devices with existing partition tables will not be used.
ceph_osd_volume: >-
  {%- set _ns = namespace() -%}
  {%- set _ns._params = [] -%}
  {%- for device, value in ansible_devices.items() -%}
  {%-   set _ns._params = _ns._params + [{ "objectstore": "bluestore", "data": "/dev/" + device }] -%}
  {%- endfor -%}
  {{ _ns._params }}

# Ceph OSD Pool to be created.
ceph_osd_pool:
  - { name: rbd, application: rbd }
  - { name: cephfs_metadata, application: cephfs, target_size_ratio: "0.4", pg_autoscale_bias: "4.0" }
  - { name: cephfs_data, application: cephfs, target_size_ratio: "0.4" }
